{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51480ff-bf0f-41cf-bdcb-af08ce5f6bd7",
   "metadata": {},
   "source": [
    "## Explore how the collect() operation works in PySpark using a dataset with basic RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8585fdcd-9c9c-4077-9685-f3197db71ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-3ONER3J:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5e49f-3890-4260-be1f-924b927d4686",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Overview\n",
    "### >Total Records: 50 students\n",
    "### >Columns: 7 â†’ id, name, age, gender, math, science, english\n",
    "### >No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7c6d6-019f-407d-aefa-d2574b18fe4b",
   "metadata": {},
   "source": [
    "## ðŸ‘¥ Demographics\n",
    "### Age: 18 â€“ 25 years (average â‰ˆ 21.5)\n",
    "### Gender: 29 Female, 21 Male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5815e6a-6f27-4c28-9499-c2ca868a183a",
   "metadata": {},
   "source": [
    "## ðŸ“š Academic Performance\n",
    "### Math:\n",
    "### Range: 40 â€“ 100\n",
    "### Mean: 68.9\n",
    "### Std. Dev.: 17.6 (high variation)\n",
    "\n",
    "### Science:\n",
    "### Range: 44 â€“ 99\n",
    "### Mean: 70.2\n",
    "### Std. Dev.: 14.6 (moderate variation)\n",
    "\n",
    "### English:\n",
    "### Range: 42 â€“ 100\n",
    "### Mean: 69.4\n",
    "### Std. Dev.: 18.7 (highest variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276a9ee-2aa0-42ba-b687-c8803c4e4c68",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "### Science is the strongest subject on average.\n",
    "### English has the most variation in performance.\n",
    "### Students perform differently across subjects (not uniform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bd1dae-50f3-4b6d-843e-f61bb639e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "# # Initialize SparkContext\n",
    "# sc = SparkContext(\"local\", \"CSV_RDD_Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8508724d-77da-4a6a-8eca-f6576771e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"C:/Users/Poojitha/Desktop/students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fab91f-fb07-48e0-9ab9-23735783f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = data.first()\n",
    "rows = data.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4034ee3f-99c8-4e59-9ea1-e824a8b2c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rdd = rows.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ce7b38-b8e5-4e19-8e10-07ff79f8d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Student Dataset (first 10 rows) ===\n",
      "['1', 'Alice', '20', 'F', '66', '92', '44']\n",
      "['2', 'Bob', '20', 'M', '82', '52', '77']\n",
      "['3', 'Charlie', '22', 'F', '43', '57', '76']\n",
      "['4', 'David', '19', 'M', '95', '69', '46']\n",
      "['5', 'Eva', '19', 'F', '62', '44', '96']\n",
      "['6', 'Frank', '22', 'F', '70', '78', '94']\n",
      "['7', 'Grace', '24', 'F', '67', '66', '93']\n",
      "['8', 'Henry', '21', 'F', '53', '82', '60']\n",
      "['9', 'Ivy', '19', 'M', '64', '52', '46']\n",
      "['10', 'Jack', '19', 'F', '44', '59', '60']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Student Dataset (first 10 rows) ===\")\n",
    "for row in split_rdd.take(10): # you can change 10 â†’ 20, 50 etc.\n",
    " print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3a390dc-8d2a-4152-a0bf-f136814efdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_rdd = split_rdd.map(lambda x: (int(x[0]), x[1], int(x[2]), x[3], int(x[4]), int(x[5]), int(x[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc0eaf0c-b6db-4a53-9eb3-f09c07cc1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_marks_rdd = students_rdd.map(lambda x: (x[1], (x[4] + x[5] + x[6]) / 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ebe1120-0de6-48df-aeae-d54b280c386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_rdd = avg_marks_rdd.filter(lambda x: x[1] >= 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6960e622-fe94-4309-baa6-8f8a7a8e1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_passed_rdd = passed_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52e8bb0c-86ac-4675-8b91-a003db39cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted_passed_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ec62a67-d977-4869-b713-400ea1b34452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Students with Average >= 75 ===\n",
      "Name: Leo, Avg Marks: 88.00\n",
      "Name: Olivia, Avg Marks: 88.00\n",
      "Name: Rita, Avg Marks: 86.67\n",
      "Name: Kathy, Avg Marks: 81.67\n",
      "Name: George, Avg Marks: 81.67\n",
      "Name: Frank, Avg Marks: 80.67\n",
      "Name: Oscar, Avg Marks: 80.00\n",
      "Name: Uma, Avg Marks: 78.33\n",
      "Name: Kyle, Avg Marks: 78.33\n",
      "Name: Matt, Avg Marks: 78.33\n",
      "Name: Tina, Avg Marks: 76.00\n",
      "Name: Victor, Avg Marks: 75.67\n",
      "Name: Grace, Avg Marks: 75.33\n",
      "Name: Mona, Avg Marks: 75.00\n",
      "Name: Will, Avg Marks: 75.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Students with Average >= 75 ===\")\n",
    "for student in results:\n",
    " print(f\"Name: {student[0]}, Avg Marks: {student[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a76c67d-bddf-45de-9567-874475cd7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of students who passed: 15\n"
     ]
    }
   ],
   "source": [
    "count_passed = passed_rdd.count()\n",
    "print(\"\\nNumber of students who passed:\", count_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e4a73dd-9f96-46f2-8cce-5bd678819a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topper: ('Olivia', 88.0)\n"
     ]
    }
   ],
   "source": [
    "topper = passed_rdd.reduce(lambda a, b: a if a[1] > b[1] else b)\n",
    "print(\"Topper:\", topper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1491234f-ee2e-4fde-8094-418d83909f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 Passed Students (via take):\n",
      "[('Frank', 80.66666666666667), ('Grace', 75.33333333333333), ('Kathy', 81.66666666666667), ('Leo', 88.0), ('Mona', 75.0)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 5 Passed Students (via take):\")\n",
    "print(passed_rdd.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550585e-4c65-4ef7-832b-0ce1c507a2dd",
   "metadata": {},
   "source": [
    "### Summary\n",
    "### Spark Context setup (sc).\n",
    "\n",
    "### Loading Dataset:\n",
    "\n",
    "#### data = sc.textFile(\"students.csv\")\n",
    "### Preprocessing:\n",
    "\n",
    "#### Removed header row.\n",
    "#### Split lines into fields.\n",
    "### Transformations:\n",
    "\n",
    "#### map() â†’ convert rows into structured format.\n",
    "#### filter() â†’ apply conditions (e.g., scores/age-based filtering).\n",
    "#### flatMap() â†’ expand data where needed.\n",
    "### Actions:\n",
    "\n",
    "#### collect() â†’ retrieve all records.\n",
    "#### count() â†’ count number of rows.\n",
    "#### first(), take(n) â†’ preview sample records.\n",
    "### Aggregations:\n",
    "\n",
    "#### reduceByKey() / groupByKey() for subject-wise or student-wise operations.\n",
    "#### Possibly word countâ€“style demo for understanding RDD basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11976ab4-2586-42f4-93b1-b707e38e124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
